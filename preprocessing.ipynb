{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import src.util as util\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = util.load_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config_data: dict) -> pd.DataFrame:\n",
    "    # Load every set of data\n",
    "    x_train = util.pickle_load(config_data[\"train_set_path\"][0])\n",
    "    y_train = util.pickle_load(config_data[\"train_set_path\"][1])\n",
    "\n",
    "    x_valid = util.pickle_load(config_data[\"valid_set_path\"][0])\n",
    "    y_valid = util.pickle_load(config_data[\"valid_set_path\"][1])\n",
    "\n",
    "    x_test = util.pickle_load(config_data[\"test_set_path\"][0])\n",
    "    y_test = util.pickle_load(config_data[\"test_set_path\"][1])\n",
    "\n",
    "    # Concatenate x and y each set\n",
    "    train_set = pd.concat([x_train, y_train], axis = 1)\n",
    "    valid_set = pd.concat([x_valid, y_valid], axis = 1)\n",
    "    test_set = pd.concat([x_test, y_test], axis = 1)\n",
    "\n",
    "    # Return 3 set of data\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = load_dataset(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Join Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_label_categori(set_data, config_data):\n",
    "    # Check if label not found in set data\n",
    "    if config_data[\"label\"] in set_data.columns.to_list():\n",
    "        # Create copy of set data\n",
    "        set_data = set_data.copy()\n",
    "\n",
    "        # Return renamed set data\n",
    "        return set_data\n",
    "    else:\n",
    "        raise RuntimeError(\"Kolom label tidak terdeteksi pada set data yang diberikan!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_nan_detector(set_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create copy of set data\n",
    "    set_data = set_data.copy()\n",
    "\n",
    "    # Replace NaN with \"UNKNOWN\" in categorical columns\n",
    "    categorical_columns = set_data.select_dtypes(include=[\"object\"]).columns\n",
    "    for column in categorical_columns:\n",
    "        set_data[column] = set_data[column].fillna(\"UNKNOWN\")\n",
    "\n",
    "    # Return replaced set data\n",
    "    return set_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numereical_nan_detector(set_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create copy of set data\n",
    "    set_data = set_data.copy()\n",
    "\n",
    "    # Replace NaN with median in numerical columns\n",
    "    numerical_columns = set_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        if set_data[column].isnull().sum() > 0:\n",
    "            median = set_data[column].median()\n",
    "            set_data[column].fillna(median, inplace=True)\n",
    "\n",
    "    # Return replaced set data\n",
    "    return set_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = categorical_nan_detector(train_set)\n",
    "train_set = numereical_nan_detector(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = categorical_nan_detector(train_set)\n",
    "valid_set = numereical_nan_detector(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = categorical_nan_detector(train_set)\n",
    "test_set = numereical_nan_detector(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encoding Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_fit_transform(data_sets: list, config: dict) -> list:\n",
    "    # Select categorical columns\n",
    "    categorical_cols = data_sets[0].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Create le objects\n",
    "    le_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "\n",
    "    # Fit and transform le for each categorical column in all data sets\n",
    "    for col in categorical_cols:\n",
    "        all_data = pd.concat([ds[col] for ds in data_sets], axis=0)\n",
    "        le_encoders[col].fit(all_data)\n",
    "        for ds in data_sets:\n",
    "            ds[col] = le_encoders[col].transform(ds[col])\n",
    "\n",
    "    # Save le objects\n",
    "    util.pickle_dump(le_encoders, config[\"le_encoder_path\"])\n",
    "\n",
    "    # Return transformed data sets\n",
    "    return data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_transform(data: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
    "    # Load le object\n",
    "    le_encoders = util.pickle_load(config[\"le_encoder_path\"])\n",
    "\n",
    "    # Find categorical columns\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Transform categorical columns with le\n",
    "    for col in categorical_cols:\n",
    "        data[col] = le_encoders[col].transform(data[col])\n",
    "\n",
    "    # Return transformed data\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = le_fit_transform([train_set, valid_set, test_set], config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = le_transform(train_set, config)\n",
    "valid_set = le_transform(valid_set, config)\n",
    "test_set = le_transform(test_set, config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dump Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.drop(columns = \"Profit\")\n",
    "\n",
    "y_train = train_set.Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.pickle_dump(x_train, \"data/processed/x_train_feng.pkl\")\n",
    "util.pickle_dump(y_train, \"data/processed/y_train_feng.pkl\")\n",
    "\n",
    "util.pickle_dump(valid_set.drop(columns = \"Profit\"), \"data/processed/x_valid_feng.pkl\")\n",
    "util.pickle_dump(valid_set.Profit, \"data/processed/y_valid_feng.pkl\")\n",
    "\n",
    "util.pickle_dump(test_set.drop(columns = \"Profit\"), \"data/processed/x_test_feng.pkl\")\n",
    "util.pickle_dump(test_set.Profit, \"data/processed/y_test_feng.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
